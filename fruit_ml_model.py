# -*- coding: utf-8 -*-
"""Fruit_ML_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lN5hma_vLL3eiv2erbEpN4wvdvH1M_dr
"""

import os
import matplotlib.pyplot as plt
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

labels = os.listdir('/content/drive/MyDrive/dataset (1)/train')
labels

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2,zoom_range=0.2,shear_range=0.3,horizontal_flip=True,brightness_range=[0.5,1.5])

tg = datagen.flow_from_directory(directory='/content/drive/MyDrive/dataset (1)/train', target_size=(224,224), classes=labels, batch_size=25, subset='training')
vg = datagen.flow_from_directory(directory='/content/drive/MyDrive/dataset (1)/train', target_size=(224,224), classes=labels, batch_size=25, subset='validation')

tg.class_indices

#Dictionary with key and correct values as labels5
image_class_dict={0:'freshbanana',
 1:'rottenapples',
 2:'rottenoranges',
 3:'freshapples',
 4:'rottenbanana',
 5:'freshoranges',
}

### Ploting Augmented Images

images,label=tg.next()
plt.figure(figsize=(20,10))
for i in range(10):
    plt.subplot(2,5,i+1)
    plt.imshow(images[i])
    plt.xticks([])
    plt.yticks([])
    l=label[i]
    for j in range(6):
        if l[j]==1:
            plt.xlabel(image_class_dict[j])
        else :
            pass

from  keras.models  import Sequential

model = Sequential()

model.get_config()

from   keras.layers import  Convolution2D

model.add(
Convolution2D(
    filters=16,
    kernel_size=(3,3),
    input_shape=(224,224,3),
    activation='relu'
)
)

from keras.layers   import  MaxPooling2D

model.add(
MaxPooling2D(pool_size=(2,2))
)

model.get_config()

model.add(
Convolution2D(
    filters=32,
    kernel_size=(3,3),
    activation='relu'
)
)

model.add(
MaxPooling2D(pool_size=(2,2))
)

model.add(
Convolution2D(
    filters=64,
    kernel_size=(3,3),
    activation='relu'
)
)

model.add(
MaxPooling2D(pool_size=(2,2))
)

from keras.layers   import Flatten

model.add(Flatten())

model.get_config()

from  keras.layers import  Dense

model.add ( Dense(units=128,  activation='relu')  )

model.add ( Dense(units=128,  activation='relu')  )

model.add ( Dense(units=6,  activation='softmax')  )

model.get_config()

model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])

model.summary()

history = model.fit(tg, steps_per_epoch=len(tg), epochs=10, validation_data=vg, validation_steps=len(vg))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Acc','Val'], loc = 'upper left')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['loss','Val'], loc = 'upper left')

from keras.preprocessing import image
test_image = image.load_img("/content/drive/MyDrive/dataset (1)/test/rottenbanana/rotated_by_15_Screen Shot 2018-06-12 at 9.06.13 PM.png", target_size = (224,224))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = m.predict(test_image)
print(result)

from keras.preprocessing import image
test_image = image.load_img("/content/drive/MyDrive/dataset (1)/test/rottenoranges/Screen Shot 2018-06-12 at 11.27.01 PM.png", target_size = (224,224))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = m.predict(test_image)
print(result)

model.save('/content/drive/MyDrive/fruit_model.h5')

from keras.models import load_model

m=load_model('/content/drive/MyDrive/fruit_model.h5')

m.predict('/content/drive/MyDrive/dataset (1)/test/rottenapples/Screen Shot 2018-06-07 at 2.15.34 PM.png')

import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_keras_model(m)
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)

